{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# MDP parameters\n",
    "GRID_SIZE = 3 \n",
    "R_X = R_Y = 0  \n",
    "\n",
    "# Define action symbols\n",
    "action_symbols = ['↑', '↓', '→', '←']  # Symbols for the four possible actions\n",
    "\n",
    "actions = action_symbols\n",
    "gamma = 0.99\n",
    "\n",
    "transition_probs = {'↑': [0.8, 0.0, 0.1, 0.1],\n",
    "                    '↓': [0, 0.8, 0.1, 0.1],\n",
    "                    '→': [0.1, 0.1, 0.8, 0],\n",
    "                    '←': [0.1, 0.1, 0, 0.8]}\n",
    "\n",
    "rewards = np.array([[0, -1, 10],\n",
    "                    [-1, -1, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n",
    "value_function = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "policy = np.zeros((GRID_SIZE, GRID_SIZE), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aed64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_position(i, j, action):\n",
    "    if action == '↑':\n",
    "        return max(i - 1, 0), j\n",
    "    elif action == '↓':\n",
    "        return min(i + 1, GRID_SIZE - 1), j\n",
    "    elif action == '→':\n",
    "        return i, min(j + 1, GRID_SIZE - 1)\n",
    "    elif action == '←':\n",
    "        return i, max(j - 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd8ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_action(i, j, action):\n",
    "    match action:\n",
    "        case '↑':\n",
    "            return i > 0\n",
    "        case '↓':\n",
    "            return i < GRID_SIZE - 1\n",
    "        case '→':\n",
    "            return j < GRID_SIZE - 1\n",
    "        case '←':\n",
    "            return j > 0\n",
    "        case _:\n",
    "            return False  # In case of an unknown action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "883b40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration():\n",
    "    theta = 0.001\n",
    "    iteration_count = 0\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for i in range(GRID_SIZE):\n",
    "            for j in range(GRID_SIZE):\n",
    "                if rewards[i][j] in {10, rewards[R_X][R_Y]}:  # Skip terminal states\n",
    "                    continue\n",
    "\n",
    "                old_value = value_function[i][j]\n",
    "                best_value = float('-inf')\n",
    "                best_action = None\n",
    "\n",
    "                for action in actions:\n",
    "                    if not valid_action(i, j, action):\n",
    "                        continue\n",
    "\n",
    "                    expected_value = rewards[i][j]\n",
    "                    for k, prob in enumerate(transition_probs[action]):\n",
    "                        ni, nj = get_new_position(i, j, action_symbols[k])\n",
    "                        expected_value += prob * gamma * value_function[ni][nj]\n",
    "\n",
    "                    if expected_value > best_value:\n",
    "                        best_value = expected_value\n",
    "                        best_action = action\n",
    "\n",
    "                value_function[i][j] = best_value\n",
    "                policy[i][j] = best_action\n",
    "                delta = max(delta, abs(old_value - best_value))\n",
    "\n",
    "        iteration_count += 1\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return iteration_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea562ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_value_iteration(reward_value):\n",
    "\n",
    "    global rewards\n",
    "    rewards[R_X][R_Y] = reward_value\n",
    "    return value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9154d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Value Function for r = 100 (Converged in 13 iterations):\n",
      "[[100.          97.20351929  10.        ]\n",
      " [ 97.20351929  94.75126763  88.20401924]\n",
      " [ 94.48181445  92.35290449  89.76213557]]\n",
      "\n",
      "Optimal Policy for r = 100\n",
      "[['r' '←' 'T']\n",
      " ['↑' '←' '↓']\n",
      " ['↑' '←' '←']]\n",
      "\n",
      "Optimal Value Function for r = 3 (Converged in 41 iterations):\n",
      "[[ 3.          8.46194904 10.        ]\n",
      " [ 5.38366785  7.11322545  8.46194227]\n",
      " [ 4.57497057  5.79414801  6.96501766]]\n",
      "\n",
      "Optimal Policy for r = 3\n",
      "[['r' '→' 'T']\n",
      " ['→' '→' '↑']\n",
      " ['→' '→' '↑']]\n",
      "\n",
      "Optimal Value Function for r = 0 (Converged in 3 iterations):\n",
      "[[ 0.          8.46193956 10.        ]\n",
      " [ 5.08334043  7.1132055   8.46193936]\n",
      " [ 4.54187018  5.79411233  6.96500905]]\n",
      "\n",
      "Optimal Policy for r = 0\n",
      "[['r' '→' 'T']\n",
      " ['→' '→' '↑']\n",
      " ['→' '→' '↑']]\n",
      "\n",
      "Optimal Value Function for r = -3 (Converged in 3 iterations):\n",
      "[[-3.          8.46193928 10.        ]\n",
      " [ 4.78307131  7.11320493  8.46193928]\n",
      " [ 4.50887324  5.79411129  6.9650088 ]]\n",
      "\n",
      "Optimal Policy for r = -3\n",
      "[['r' '→' 'T']\n",
      " ['→' '→' '↑']\n",
      " ['→' '→' '↑']]\n"
     ]
    }
   ],
   "source": [
    "r_values = [100, 3, 0, -3]\n",
    "for r in r_values:\n",
    "    value_function[R_X, R_Y] = r\n",
    "    value_function[0, -1] = 10\n",
    "\n",
    "\n",
    "    num_iterations = run_value_iteration(r)\n",
    "\n",
    "    print(f\"\\nOptimal Value Function for r = {r} (Converged in {num_iterations} iterations):\")\n",
    "    print(value_function)\n",
    "    policy[R_X, R_Y] = 'r'\n",
    "    policy[0,-1] = 'T'\n",
    "    print(f\"\\nOptimal Policy for r = {r}\")\n",
    "    print(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blabla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
